
\documentclass[11pt]{amsart}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{epstopdf}
\usepackage{color}
\usepackage[comma,authoryear]{natbib}
%\usepackage{parskip}
\usepackage{times} % will use Times font instead of the default, saving significant space.
\usepackage{url}
\urlstyle{same}
\addtolength{\textheight}{3cm}
\setlength{\oddsidemargin}{9pt} 
\setlength{\evensidemargin}{9pt}
\linespread{1.3}

\newcommand{\mone}{\mu^1}
\newcommand{\mtwo}{\mu^2}
\newcommand{\mpi}{\mu^{\pi(i)}}
\newcommand{\ei}{\epsilon^i}
\newcommand{\Bul}{B_{u,l}}
\newtheorem{definition}{Definition}
\newcommand{\bumpsum}{\Delta}
\newcommand{\tj}{\theta_j}
\newcommand{\ti}{\theta_i}
\newcommand{\tk}{\theta_k}
\newcommand{\yti}{Y_{\theta_i}}
\newcommand{\ytil}{Y_{\theta_i,l}}

%\newcommand{}{\!}{Y_}



\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}
\begin{document}
\section{Single voxel model}
DTI observations are used to estimate flow parameters at high angular densities. 
Each observation can be modeled as a sum of individual angular flow contributions. 
Angular flow at each voxel can therefore be estimated using non-negative solvers for the linear model. 
The resulting design matrix is unfortunately ill-conditioned, requiring additional regularization of the solution space. 
The resulting angular pattern depends strongly on the regularization chosen. 
In particular, L1 or otherwise sparse solutions are unstable. 

We hope to somewhat increase the conditioning of the design matrix by adding observations 
from neighboring voxels. We extend the models to describe the dependence of 
an angular observation on the flow parameters of a different voxel. Neighbors 
that are aligned in the direction of the flow should be effected by the parameters,  
whereas neighbors perpendicular to an observed flow should not be. 

\subsection{Notation}

At this stage, we are interested in estimating the flow parameters at a 
specific voxel using data from several different voxels. 
For reference, we call the voxel of interest voxel 0. 
Flow in our voxel is discretized into onto a dense sampling of angles $\{\tj\}_{j \in \mathcal{J}}$. 
We represent flow with real-valued parameters $\beta_{\tj}\geq 0$.
Neighboring voxels are represented with relation to voxel $0$, indexed by $l \in \mathcal{L} = \{0,-1,1\}^3$. 
We add the voxel index to the parameter $\beta_{\tj, l}$ to denote the flow at neighbor $l$. 
$\|l\|$ is the distance between $(0,0,0)$ and $l$.

DTI at each voxel is measured in directions $\{\ti\}_{ i \in \mathcal{I}}$ resulting in  $B = |\mathcal{I}| $ observations per voxel.  
$\yti$ denotes the observation at direction $\ti$ for the voxel 0, and $\ytil$ for the 
measurement at neighbor $l$. 

\subsection{The model}
The effects of local flow on local observations are described by the standard model:
\begin{equation}
\yti = \sum_{j \in \mathcal{J}} \beta_{\tj} \cdot f(b, \alpha(\ti, \tj)) + \epsilon_i 
\label{basicEq}
\end{equation}
where 
\begin{enumerate}
\item The parameters $\beta_{\theta_1},...,\beta_{\tj}$ represent directional flow in a single voxel. 
\item $\alpha(\ti, \tj)$ is the angle between $\ti$ and $\tj$.
\item The function $f(b, \alpha(\ti, \tj))$ is the Stejskal-Tanner equation $e^{-b D}$, which describes the 
angular effect of flow on observation.  
$b$ is a known (and tunable) parameter of the measurement procedure.   
\item $\epsilon_i $ represents the known and unknown measurement errors (for now we don't 
tease these apart). We assume the $\epsilon_i$'s are iid, with $0$ mean and $\sigma^2$ variance.
\end{enumerate}

\subsection{Expanding the model to neighboring voxels}.
Our goal is to express an observation at voxel $l$, $\ytil$ in terms of the parameters 
of voxel 0. For voxel $l$, the relationship described in Eq \eqref{basicEq} still holds:
\begin{equation}
\ytil = \sum_{j \in \mathcal{J}} \beta_{\tj,l} \cdot f(b, \alpha(\ti, \tj)) + \epsilon_{i,l} 
\label{neighbor}
\end{equation}
However, we don't want to estimate the parameters at voxel $l$.
Instead, we try to replace them with their linear approximation based on the $\beta_{\tj}$'s. 
The resulting linear equations can explain less of the variance in the observations compared to the original
equations for voxel 0. First we discuss the linear approximation for the mean, 
then we briefly discuss the added variance due to approximation error. 

\subsubsection{A linear approximation}
We aim for their best linear approximation of $\beta_{\tj,l}$ using the 
parameters from voxel 0
\begin{equation}
\hat{\beta}_{\tj,l} = c_{\tj,l} + \sum_{k\in\mathcal{J}} w_{\tj,\tk, l} \cdot \beta_{\tk}. 
\end{equation} 

The $w$ weights represent the amount of information carried over from the flow in a neighboring voxel. 
An example for the weight function could be
\[ w_{\tj,\tk, l}  = cos(\alpha(l,\tk)) \cdot cos(\alpha(l, \tj)) \cdot e^{-\|l\|/\tau}, \]
in which $\tj, \tk$, and $l$ need to be roughly aligned for information to carry over. 
Alternatively, we might want to use normalized weights, as in 
\[\tilde{w}_{\tj,\tk, l}  = \frac{w_{\tj,\tk, l}}{\sum_\mathcal{k \in \mathcal{J}} w_{\tj,\theta_{k'}, l}} \]

We still need to reformulate Equation \eqref{neighbor} as a linear model in the original parameter vector $\beta_{\tj}$.
\begin{eqnarray*}
E[\ytil] = & \sum_{j \in \mathcal{J}}  f(b, \alpha(\ti, \tj)) \textcolor{blue}{\hat{\beta}}_{\tk,l} \\
 = & \sum_{j \in \mathcal{J}} ( \sum_{k\in\mathcal{J}} f(b, \alpha(\ti, \tj)) ( w_{\tj,\tk, l} \cdot \beta_{\tk} + c_{\tj,l})\\
 = & c_{\ti,l} +  \sum_{k\in\mathcal{J}}  \beta_{\tk}  (\sum_{j \in \mathcal{J}}  f(b, \alpha(\ti, \tj))  w_{\tj,\tk, l})\\
  = & c_{\ti,l} +  \sum_{j\in\mathcal{J}}  \beta_{\tj}  (\sum_{k\in \mathcal{J}}  f(b, \alpha(\ti, \tk))  w_{\tk,\tj, l}).
\end{eqnarray*}   
The weights of the flow parameters $\beta_{\tj}$ in the new equation are determined by a convolution of two function: 
the response function $f$, and the directional smoothness of flow $w$. 
The convolution is computed along the discretized sphere $\{\tk\}_{k \in \mathcal{J}}$. 
We can use the shorthand $f_{\ti,b}* w_{\tj,l}$ and write
\footnote{The notational abuse of $\ti$ and $\tj$ is evident here. We should consider changing to $\theta_{(j)}$ or instead assume $\mathcal{I}=\mathcal{J}$.} 
\begin{equation}
E[\ytil]  = c_{\ti,l} +  \beta_{\theta_1} \cdot f_{\ti,b}* w_{\theta_1,l}+ ... +\beta_{\theta_{|\mathcal{J}|}} \cdot f_{\ti,b}* w_{\theta_{|\mathcal{J}|},l}.
\end{equation}
From spherical symmetry arguments, $f_{\ti,b}*w_{\tj,l}$ is invariant to joint rotations of $(\ti,\tj, l)$.

\textbf{Comment} The model should extend smoothly to the $\| l\| = 0$ case in Equation \eqref{basicEq}. 
That would put the following two additional constraints on the weights: 
\begin{itemize}
\item Require that the $w_{\tj,\tk,l}$ increase to 1 as $\|l\| \to 0$ if $\tj=\tk$, and decrease towards 0 otherwise.
\item The norm of the weight vector $w_{\tj,\tk,l}$ should increase towards 1 as $\|l\|$ goes to 0. 
\end{itemize}

Compared to the local equations \eqref{basicEq}, the neighbor equation introduces an additional source of variation. 
The flow quantities causing the observed physical effect where replaced in the neighbor model with their lossy approximations.
The extra error needs to be accounted for. 
The weighted least squares algorithm optimally combines stochastic equations with different errors by
down weighing observations with more variance. In the next section we show that rotational symmetry 
allows us to use few parameters to model this additional variance. 

\subsubsection{Extra variability}
More exactly, we take a \emph{quasi-Bayesian} approach \footnote{The term is not technical, rather used here to point to an inconsistency}
in modeling the parameters $\beta_{\tj,l}$
\begin{equation}
\beta_{\tj,l} = \underbrace{c_{\tj,l} + \sum_{k\in\mathcal{J}} w_{\theta_j,\theta_k, l} \cdot \beta_{\tj}}_{\hat{\beta}_{\tj,l}} + \nu_{j,l}, 
\label{rexpress}
\end{equation}
where $\nu_{j,l}$ represents the error in the representation of $\beta_{\tj,l}$ based on its neighbors. 
If the parametric grid $\{\tj\}_\mathcal{J}$ is uniform on the sphere, the overall magnitude of approximation error 
should only depend on $l$. 

Substituting Equation \eqref{rexpress} into \eqref{neighbor} we get
\begin{equation}
\ytil = \sum_{j \in \mathcal{J}} \textcolor{blue}{\hat{\beta}}_{\tj,l} \cdot f(b, \alpha(\ti, \tj)) + \epsilon_{i,l} +  \textcolor{blue}{\omega_{i,l}}.
\end{equation}
The extra term $\omega_i$ represents the aggregated approximation errors $\nu_{j,l}$ through
\[ \omega_{i,l} = \sum_{k\in\mathcal{J}} \nu_{j,i} \cdot f(b, \alpha(\ti, \tj)).\]
I'm not sure the variance due to approximation ($var(\omega_{i,l}$) is tractable, but it should be one parameter per $\|l\|$. 

\subsubsection{The full linear model for the data}




%\bibliography{ISF}{}
%\bibliographystyle{plain}
\end{document}  
